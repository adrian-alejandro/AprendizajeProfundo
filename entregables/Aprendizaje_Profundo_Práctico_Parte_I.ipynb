{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/adrian-alejandro/AprendizajeProfundo/blob/master/entregables/Aprendizaje_Profundo_Pr%C3%A1ctico_Parte_I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yE-FKAMPlWFr"
   },
   "source": [
    "# Aprendizaje Profundo - Práctico (Parte I)\n",
    "\n",
    "Equipo: Mariana Pereyra - Adrián Zelaya\n",
    "\n",
    "Link al [repo de GitHub](https://github.com/adrian-alejandro/AprendizajeProfundo/tree/master/entregables).\n",
    "\n",
    "____\n",
    "\n",
    "Algunas consideraciones a tener en cuenta para estructurar el trabajo:\n",
    "\n",
    "1. Hacer un preprocesamiento de los datos (¿Cómo vamos a representar los datos de entrada y las categorías?).\n",
    "2. Tener un manejador del dataset (alguna clase o función que nos divida los datos en batches).\n",
    "3. Crear una clase para el modelo que se pueda instanciar con diferentes hiperparámetros\n",
    "4. Hacer logs de entrenamiento (reportar tiempo transcurrido, iteraciones/s, loss, accuracy, etc.). Usar MLFlow.\n",
    "5. Hacer un gráfico de la función de loss a lo largo de las epochs. MLFlow también puede generar la gráfica.\n",
    "6. Reportar performance en el conjunto de test con el mejor modelo entrenado. La métrica para reportar será balanced accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0cBwuyDydRL"
   },
   "source": [
    "## Objetivo\n",
    "\n",
    "En este práctico implementaremos una red neuronal simple (MLP) que asigne una categoría dado un título.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rN_dSjFulWFv"
   },
   "source": [
    "### Descarga de datos \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHqY4svlsojZ"
   },
   "source": [
    "Definimos el entorno de trabajo: local o Google Colab. En el caso del último, procedemos a montarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzb-ckFLtdxf",
    "outputId": "b5b9e240-8c4c-48e4-e6f5-937a26d77413"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive \n",
    "    drive.mount('/content/drive')\n",
    "    DATA_PATH = \"/content/drive/MyDrive/Diplomatura/Aprendizaje Profundo\"\n",
    "    MLFLOW_PATH = \"/content/mlruns\"\n",
    "    IMAGES_PATH = \"/content/images\"\n",
    "except:\n",
    "    DATA_PATH = \"data\"\n",
    "    MLFLOW_PATH = \"mlruns\"\n",
    "    IMAGES_PATH = \"images\"\n",
    "    \n",
    "MLFLOW_PATH_ZIP =  MLFLOW_PATH + \".zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtjDogApCTzP"
   },
   "source": [
    "Descargamos los datos localmente usando los siguientes comandos:\n",
    "\n",
    "```\n",
    "!curl -L https://cs.famaf.unc.edu.ar/\\~ccardellino/resources/diplodatos/meli-challenge-2019.tar.bz2 -o ./data/meli-challenge-2019.tar.bz2\n",
    "!tar jxvf ./data/meli-challenge-2019.tar.bz2 -C ./data/\n",
    "```\n",
    "\n",
    "Luego los dividimos en train y test utilizando la siguiente [notebook](https://github.com/DiploDatos/AprendizajeProfundo/blob/master/experiment/preprocess_meli_data.ipynb).\n",
    "\n",
    "Adicionalmente, dado que el dataset está en Español, descargamos el embedding preentrenado del [Spanish Billion Word (SBW)](https://crscardellino.ar/SBWCE/):\n",
    "\n",
    "```\n",
    "!curl -L https://cs.famaf.unc.edu.ar/~ccardellino/SBWCE/SBW-vectors-300-min5.txt.bz2 -o SBW-vectors-300-min5.txt.bz2\n",
    "```\n",
    "\n",
    "Finalmente subimos estos archivos a una carpeta de drive para utilizarlos desde Google Colab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lB_580RhgWjP"
   },
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bo8XqeYruEbg"
   },
   "source": [
    "Instalamos/actualizamos las siguientes librerías, por las dudas no estén actualizadas/instaladas en Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tpGnYpSMuNOG",
    "outputId": "2f24f577-9032-44c0-be8a-d690c8ff5036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (4.2.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from gensim) (6.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from gensim) (1.23.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from gensim) (1.8.1)\n",
      "Requirement already satisfied: mlflow in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (1.28.0)\n",
      "Requirement already satisfied: pandas<2 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from mlflow) (1.4.4)\n",
      "Requirement already satisfied: entrypoints<1 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from mlflow) (0.4)\n",
      "Requirement already satisfied: querystring-parser<2 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from mlflow) (6.0)\n",
      "Requirement already satisfied: sqlalchemy<2,>=1.4.0 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from mlflow) (1.4.41)\n",
      "Requirement already satisfied: pytz<2023 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from mlflow) (2022.2.1)\n",
      "Requirement already satisfied: Flask<3 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from mlflow) (2.2.2)\n",
      "Requirement already satisfied: prometheus-flask-exporter<1 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from mlflow) (0.20.3)\n",
      "Requirement already satisfied: gitpython<4,>=2.1.0 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from mlflow) (3.1.27)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from mlflow) (3.19.6)\n",
      "Requirement already satisfied: packaging<22 in /app/lib/python3.10/site-packages (from mlflow) (21.3)\n",
      "Requirement already satisfied: gunicorn<21 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from mlflow) (20.1.0)\n",
      "Requirement already satisfied: cloudpickle<3 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from mlflow) (2.2.0)\n",
      "Requirement already satisfied: docker<6,>=4.0.0 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from mlflow) (5.0.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from mlflow) (0.4.2)\n",
      "Requirement already satisfied: numpy<2 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from mlflow) (1.23.3)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /app/lib/python3.10/site-packages (from mlflow) (2.28.1)\n",
      "Requirement already satisfied: alembic<2 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from mlflow) (1.8.1)\n",
      "Collecting importlib-metadata!=4.7.0,<5,>=3.7.0\n",
      "  Using cached importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from mlflow) (8.1.3)\n",
      "Requirement already satisfied: databricks-cli<1,>=0.8.7 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from mlflow) (0.17.3)\n",
      "Requirement already satisfied: scipy<2 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from mlflow) (1.8.1)\n",
      "Requirement already satisfied: Mako in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from alembic<2->mlflow) (1.2.2)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.1)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.8.10)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.4.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from docker<6,>=4.0.0->mlflow) (1.4.1)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from Flask<3->mlflow) (2.2.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from Flask<3->mlflow) (2.1.2)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from Flask<3->mlflow) (3.1.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from gitpython<4,>=2.1.0->mlflow) (4.0.9)\n",
      "Requirement already satisfied: setuptools>=3.0 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from gunicorn<21->mlflow) (60.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /app/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<5,>=3.7.0->mlflow) (3.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /app/lib/python3.10/site-packages (from packaging<22->mlflow) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from pandas<2->mlflow) (2.8.2)\n",
      "Requirement already satisfied: prometheus-client in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from prometheus-flask-exporter<1->mlflow) (0.14.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /app/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /app/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /app/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /app/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from sqlalchemy<2,>=1.4.0->mlflow) (1.1.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/adrian/PycharmProjects/AprendizajeProfundo/venv/lib/python3.10/site-packages (from Jinja2>=3.0->Flask<3->mlflow) (2.1.1)\n",
      "Installing collected packages: importlib-metadata\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 5.1.0\n",
      "    Not uninstalling importlib-metadata at /app/lib/python3.10/site-packages, outside environment /home/adrian/PycharmProjects/AprendizajeProfundo/venv\n",
      "    Can't uninstall 'importlib-metadata'. No files were found to uninstall.\n",
      "Successfully installed importlib-metadata-4.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim --upgrade \n",
    "!pip install mlflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tREtYNV2tgw"
   },
   "source": [
    "Importamos las librerías necesarias para nuestro análisis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PhX0iO4ilWFw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import functools\n",
    "import json\n",
    "import gzip\n",
    "import bz2\n",
    "import tempfile\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.parsing import preprocessing\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dxXwf9c3h77"
   },
   "source": [
    "Chequeamos si hay GPU disponible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Fp3xNfTX3PM",
    "outputId": "53c58eb0-886d-4329-dc89-53025dbe596e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)\n",
    "device = torch.device('cuda') if use_cuda else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBTX6HOa3pg8"
   },
   "source": [
    "Actualizamos los paths de los datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "bpOmFleDt0KQ"
   },
   "outputs": [],
   "source": [
    "path_meli_train = os.path.join(DATA_PATH, \"meli-challenge-2019\", \"spanish.train.jsonl.gz\")\n",
    "path_meli_validation = os.path.join(DATA_PATH, \"meli-challenge-2019\", \"spanish.validation.jsonl.gz\")\n",
    "path_meli_test = os.path.join(DATA_PATH, \"meli-challenge-2019\", \"spanish.test.jsonl.gz\")\n",
    "path_embedding = os.path.join(DATA_PATH, \"SBW-vectors-300-min5.txt.bz2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sUqaqdElWFx"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "Nos basaremos en el dataset del MeLi Data Challenge 2019 para trabajar en el problema de clasificación de texto de este práctico.\n",
    "\n",
    "El dataset contiene información acerca de los títulos de publicaciones, categorías de las mismas, información de idioma y confiabilidad de la anotación. Cuenta con anotaciones de títulos para 632 categorías distintas.\n",
    "\n",
    "El dataset también cuenta con una partición de test que está compuesta de 636,680 de ejemplos con las mismas categorías (aunque no necesariamente la misma distribución).\n",
    "\n",
    "También hay datos en idioma portugués, aunque para este práctico nos centraremos solamente en el idioma español."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUoaY6VH0vcG"
   },
   "source": [
    "Para trabajar con el conjuntos de datos en PyTorch se podría utilizar la clase  IterableDataset. Esta elección se debe a que esta clase permite trabajar más eficientemente con un conjunto de datos grade, como es el caso del MeLi Challenge. Pero por cuestiones de simplicidad usaremos Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Vl4fjBwQlWFy"
   },
   "outputs": [],
   "source": [
    "class MeLiChallengeDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if torch.is_tensor(item):\n",
    "            item = item.to_list()\n",
    "        \n",
    "        item = {\n",
    "            \"data\": self.dataset.loc[item, \"title\"],\n",
    "            \"target\": self.dataset.loc[item, \"category\"]\n",
    "        }\n",
    "        \n",
    "        if self.transform:\n",
    "            item = self.transform(item)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38NqQ_zuJ8X8"
   },
   "source": [
    "Inspeccionamos la data de train usando Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "WgxG1uGNDYWs",
    "outputId": "021dd878-0cf0-40a0-c97b-52cdc58d0659"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>split</th>\n",
       "      <th>tokenized_title</th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "      <th>n_labels</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spanish</td>\n",
       "      <td>reliable</td>\n",
       "      <td>Casita Muñecas Barbies Pintadas</td>\n",
       "      <td>DOLLHOUSES</td>\n",
       "      <td>train</td>\n",
       "      <td>[casita, muñecas, barbies, pintadas]</td>\n",
       "      <td>[50001, 2, 50000, 3]</td>\n",
       "      <td>0</td>\n",
       "      <td>632</td>\n",
       "      <td>4895280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spanish</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>Neceser Cromado Holográfico</td>\n",
       "      <td>TOILETRY_BAGS</td>\n",
       "      <td>train</td>\n",
       "      <td>[neceser, cromado, holográfico]</td>\n",
       "      <td>[6, 4, 5]</td>\n",
       "      <td>1</td>\n",
       "      <td>632</td>\n",
       "      <td>4895280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spanish</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>Funda Asiento A Medida D20 Chevrolet</td>\n",
       "      <td>CAR_SEAT_COVERS</td>\n",
       "      <td>train</td>\n",
       "      <td>[funda, asiento, medida, chevrolet]</td>\n",
       "      <td>[9, 7, 10, 8]</td>\n",
       "      <td>2</td>\n",
       "      <td>632</td>\n",
       "      <td>4895280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spanish</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>Embrague Ford Focus One 1.8 8v Td (90cv) Desde...</td>\n",
       "      <td>AUTOMOTIVE_CLUTCH_KITS</td>\n",
       "      <td>train</td>\n",
       "      <td>[embrague, ford, focus, one]</td>\n",
       "      <td>[11, 13, 12, 14]</td>\n",
       "      <td>3</td>\n",
       "      <td>632</td>\n",
       "      <td>4895280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spanish</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>Bateria Panasonic Dmwbcf10 Lumix Dmc-fx60n Dmc...</td>\n",
       "      <td>CAMERA_BATTERIES</td>\n",
       "      <td>train</td>\n",
       "      <td>[bateria, panasonic, dmwbcf, lumix, dmc, fxn, ...</td>\n",
       "      <td>[15, 19, 17, 18, 16, 1, 1, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>632</td>\n",
       "      <td>4895280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language label_quality                                              title  \\\n",
       "0  spanish      reliable                    Casita Muñecas Barbies Pintadas   \n",
       "1  spanish    unreliable                       Neceser Cromado Holográfico    \n",
       "2  spanish    unreliable               Funda Asiento A Medida D20 Chevrolet   \n",
       "3  spanish    unreliable  Embrague Ford Focus One 1.8 8v Td (90cv) Desde...   \n",
       "4  spanish    unreliable  Bateria Panasonic Dmwbcf10 Lumix Dmc-fx60n Dmc...   \n",
       "\n",
       "                 category  split  \\\n",
       "0              DOLLHOUSES  train   \n",
       "1           TOILETRY_BAGS  train   \n",
       "2         CAR_SEAT_COVERS  train   \n",
       "3  AUTOMOTIVE_CLUTCH_KITS  train   \n",
       "4        CAMERA_BATTERIES  train   \n",
       "\n",
       "                                     tokenized_title  \\\n",
       "0               [casita, muñecas, barbies, pintadas]   \n",
       "1                    [neceser, cromado, holográfico]   \n",
       "2                [funda, asiento, medida, chevrolet]   \n",
       "3                       [embrague, ford, focus, one]   \n",
       "4  [bateria, panasonic, dmwbcf, lumix, dmc, fxn, ...   \n",
       "\n",
       "                            data  target  n_labels     size  \n",
       "0           [50001, 2, 50000, 3]       0       632  4895280  \n",
       "1                      [6, 4, 5]       1       632  4895280  \n",
       "2                  [9, 7, 10, 8]       2       632  4895280  \n",
       "3               [11, 13, 12, 14]       3       632  4895280  \n",
       "4  [15, 19, 17, 18, 16, 1, 1, 1]       4       632  4895280  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([x for x in pd.read_json(path_meli_train, lines=True, chunksize=100000)], ignore_index=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BlabanLEphyL",
    "outputId": "a459bcf2-083f-4f46-961b-944cf7c1bea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 387237 registros que tienen etiquetas confiables y 4508043 registros que no, es decir un 8.59% tiene etiquetas confiables.\n"
     ]
    }
   ],
   "source": [
    "unreliable = train_df.label_quality.value_counts()[0]\n",
    "reliable = train_df.label_quality.value_counts()[1]\n",
    "\n",
    "print(f\"Hay {reliable} registros que tienen etiquetas confiables y {unreliable} registros que no, es decir un {round(reliable/unreliable*100,2)}% tiene etiquetas confiables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspeccionamos la data de Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "1g1wOdVHIjOe",
    "outputId": "12cc8454-696f-40da-da29-4bc075cae159"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>split</th>\n",
       "      <th>tokenized_title</th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "      <th>n_labels</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spanish</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>Metal Biela Dw10 Hdi 2.0</td>\n",
       "      <td>ENGINE_BEARINGS</td>\n",
       "      <td>validation</td>\n",
       "      <td>[metal, biela, hdi]</td>\n",
       "      <td>[457, 1480, 3450]</td>\n",
       "      <td>88</td>\n",
       "      <td>632</td>\n",
       "      <td>1223820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spanish</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>Repuestos Martillo Rotoprcutor Bosch Gshsce Po...</td>\n",
       "      <td>ELECTRIC_DEMOLITION_HAMMERS</td>\n",
       "      <td>validation</td>\n",
       "      <td>[repuestos, martillo, rotoprcutor, bosch, gshs...</td>\n",
       "      <td>[3119, 892, 1, 767, 1, 9337]</td>\n",
       "      <td>174</td>\n",
       "      <td>632</td>\n",
       "      <td>1223820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spanish</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>Pesca Caña Pejerrey Colony Brava 3m Fibra De V...</td>\n",
       "      <td>FISHING_RODS</td>\n",
       "      <td>validation</td>\n",
       "      <td>[pesca, caña, pejerrey, colony, brava, fibra, ...</td>\n",
       "      <td>[700, 990, 2057, 3990, 3670, 1737, 1153, 6568]</td>\n",
       "      <td>313</td>\n",
       "      <td>632</td>\n",
       "      <td>1223820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spanish</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>Porcelanato Abitare Be 20x120 Cm. Ceramica Por...</td>\n",
       "      <td>PORCELAIN_TILES</td>\n",
       "      <td>validation</td>\n",
       "      <td>[porcelanato, abitare, ceramica, portinari]</td>\n",
       "      <td>[2722, 4404, 1406, 4405]</td>\n",
       "      <td>427</td>\n",
       "      <td>632</td>\n",
       "      <td>1223820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spanish</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>Reconstruction Semi Di Lino Alfaparf Shampoo 1...</td>\n",
       "      <td>HAIR_SHAMPOOS_AND_CONDITIONERS</td>\n",
       "      <td>validation</td>\n",
       "      <td>[reconstruction, semi, lino, alfaparf, shampoo]</td>\n",
       "      <td>[1, 3365, 7502, 10919, 849]</td>\n",
       "      <td>194</td>\n",
       "      <td>632</td>\n",
       "      <td>1223820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language label_quality                                              title  \\\n",
       "0  spanish    unreliable                           Metal Biela Dw10 Hdi 2.0   \n",
       "1  spanish    unreliable  Repuestos Martillo Rotoprcutor Bosch Gshsce Po...   \n",
       "2  spanish    unreliable  Pesca Caña Pejerrey Colony Brava 3m Fibra De V...   \n",
       "3  spanish    unreliable  Porcelanato Abitare Be 20x120 Cm. Ceramica Por...   \n",
       "4  spanish    unreliable  Reconstruction Semi Di Lino Alfaparf Shampoo 1...   \n",
       "\n",
       "                         category       split  \\\n",
       "0                 ENGINE_BEARINGS  validation   \n",
       "1     ELECTRIC_DEMOLITION_HAMMERS  validation   \n",
       "2                    FISHING_RODS  validation   \n",
       "3                 PORCELAIN_TILES  validation   \n",
       "4  HAIR_SHAMPOOS_AND_CONDITIONERS  validation   \n",
       "\n",
       "                                     tokenized_title  \\\n",
       "0                                [metal, biela, hdi]   \n",
       "1  [repuestos, martillo, rotoprcutor, bosch, gshs...   \n",
       "2  [pesca, caña, pejerrey, colony, brava, fibra, ...   \n",
       "3        [porcelanato, abitare, ceramica, portinari]   \n",
       "4    [reconstruction, semi, lino, alfaparf, shampoo]   \n",
       "\n",
       "                                             data  target  n_labels     size  \n",
       "0                               [457, 1480, 3450]      88       632  1223820  \n",
       "1                    [3119, 892, 1, 767, 1, 9337]     174       632  1223820  \n",
       "2  [700, 990, 2057, 3990, 3670, 1737, 1153, 6568]     313       632  1223820  \n",
       "3                        [2722, 4404, 1406, 4405]     427       632  1223820  \n",
       "4                     [1, 3365, 7502, 10919, 849]     194       632  1223820  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df = pd.concat([x for x in pd.read_json(path_meli_validation, lines=True, chunksize=100000)], ignore_index=True)\n",
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eObIuQe3KQOr"
   },
   "source": [
    "Inspeccionamos la data de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3kVugbNLKSgU",
    "outputId": "f145999d-ba3e-4094-efd6-dea0d841eefa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>split</th>\n",
       "      <th>tokenized_title</th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "      <th>n_labels</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spanish</td>\n",
       "      <td>reliable</td>\n",
       "      <td>Mochilas Maternales Bolsos Bebe Simil Cuero Ma...</td>\n",
       "      <td>DIAPER_BAGS</td>\n",
       "      <td>test</td>\n",
       "      <td>[mochilas, maternales, bolsos, bebe, simil, cu...</td>\n",
       "      <td>[5650, 5271, 5268, 915, 2724, 375, 37363]</td>\n",
       "      <td>318</td>\n",
       "      <td>632</td>\n",
       "      <td>63680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spanish</td>\n",
       "      <td>reliable</td>\n",
       "      <td>Bolso Maternal/bebe Incluye Cambiador + Correa...</td>\n",
       "      <td>DIAPER_BAGS</td>\n",
       "      <td>test</td>\n",
       "      <td>[bolso, maternal, bebe, incluye, cambiador, co...</td>\n",
       "      <td>[502, 2742, 915, 3031, 2740, 1840, 4635]</td>\n",
       "      <td>318</td>\n",
       "      <td>632</td>\n",
       "      <td>63680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spanish</td>\n",
       "      <td>reliable</td>\n",
       "      <td>Mochila Maternal Land  + Gancho Envio Gratis-cc</td>\n",
       "      <td>DIAPER_BAGS</td>\n",
       "      <td>test</td>\n",
       "      <td>[mochila, maternal, land, gancho, envio, gratis]</td>\n",
       "      <td>[337, 2742, 2741, 3303, 211, 1429]</td>\n",
       "      <td>318</td>\n",
       "      <td>632</td>\n",
       "      <td>63680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spanish</td>\n",
       "      <td>reliable</td>\n",
       "      <td>Bolso Maternal Moderno Con Cambiador Y Correa ...</td>\n",
       "      <td>DIAPER_BAGS</td>\n",
       "      <td>test</td>\n",
       "      <td>[bolso, maternal, moderno, cambiador, correa, ...</td>\n",
       "      <td>[502, 2742, 2983, 2740, 1840, 476, 2990]</td>\n",
       "      <td>318</td>\n",
       "      <td>632</td>\n",
       "      <td>63680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spanish</td>\n",
       "      <td>reliable</td>\n",
       "      <td>Bolso Maternal Moderno Con Cambiador Y Correa ...</td>\n",
       "      <td>DIAPER_BAGS</td>\n",
       "      <td>test</td>\n",
       "      <td>[bolso, maternal, moderno, cambiador, correa, ...</td>\n",
       "      <td>[502, 2742, 2983, 2740, 1840, 4635]</td>\n",
       "      <td>318</td>\n",
       "      <td>632</td>\n",
       "      <td>63680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language label_quality                                              title  \\\n",
       "0  spanish      reliable  Mochilas Maternales Bolsos Bebe Simil Cuero Ma...   \n",
       "1  spanish      reliable  Bolso Maternal/bebe Incluye Cambiador + Correa...   \n",
       "2  spanish      reliable    Mochila Maternal Land  + Gancho Envio Gratis-cc   \n",
       "3  spanish      reliable  Bolso Maternal Moderno Con Cambiador Y Correa ...   \n",
       "4  spanish      reliable  Bolso Maternal Moderno Con Cambiador Y Correa ...   \n",
       "\n",
       "      category split                                    tokenized_title  \\\n",
       "0  DIAPER_BAGS  test  [mochilas, maternales, bolsos, bebe, simil, cu...   \n",
       "1  DIAPER_BAGS  test  [bolso, maternal, bebe, incluye, cambiador, co...   \n",
       "2  DIAPER_BAGS  test   [mochila, maternal, land, gancho, envio, gratis]   \n",
       "3  DIAPER_BAGS  test  [bolso, maternal, moderno, cambiador, correa, ...   \n",
       "4  DIAPER_BAGS  test  [bolso, maternal, moderno, cambiador, correa, ...   \n",
       "\n",
       "                                        data  target  n_labels   size  \n",
       "0  [5650, 5271, 5268, 915, 2724, 375, 37363]     318       632  63680  \n",
       "1   [502, 2742, 915, 3031, 2740, 1840, 4635]     318       632  63680  \n",
       "2         [337, 2742, 2741, 3303, 211, 1429]     318       632  63680  \n",
       "3   [502, 2742, 2983, 2740, 1840, 476, 2990]     318       632  63680  \n",
       "4        [502, 2742, 2983, 2740, 1840, 4635]     318       632  63680  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.concat([x for x in pd.read_json(path_meli_test, lines=True, chunksize=100000)], ignore_index=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = False\n",
    "if TEST:\n",
    "    train_data = train_df.iloc[:10000, :]\n",
    "    validation_data = validation_df.iloc[:1000, :]\n",
    "    test_data = test_df.iloc[:1000, :]\n",
    "else:\n",
    "    train_data = train_df.copy()\n",
    "    validation_data = validation_df.copy()\n",
    "    test_data = test_df.copy()\n",
    "    \n",
    "df_concat = [train_data, validation_data, test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>split</th>\n",
       "      <th>tokenized_title</th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "      <th>n_labels</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spanish</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>Metal Biela Dw10 Hdi 2.0</td>\n",
       "      <td>ENGINE_BEARINGS</td>\n",
       "      <td>validation</td>\n",
       "      <td>[metal, biela, hdi]</td>\n",
       "      <td>[457, 1480, 3450]</td>\n",
       "      <td>88</td>\n",
       "      <td>632</td>\n",
       "      <td>1223820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spanish</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>Repuestos Martillo Rotoprcutor Bosch Gshsce Po...</td>\n",
       "      <td>ELECTRIC_DEMOLITION_HAMMERS</td>\n",
       "      <td>validation</td>\n",
       "      <td>[repuestos, martillo, rotoprcutor, bosch, gshs...</td>\n",
       "      <td>[3119, 892, 1, 767, 1, 9337]</td>\n",
       "      <td>174</td>\n",
       "      <td>632</td>\n",
       "      <td>1223820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spanish</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>Pesca Caña Pejerrey Colony Brava 3m Fibra De V...</td>\n",
       "      <td>FISHING_RODS</td>\n",
       "      <td>validation</td>\n",
       "      <td>[pesca, caña, pejerrey, colony, brava, fibra, ...</td>\n",
       "      <td>[700, 990, 2057, 3990, 3670, 1737, 1153, 6568]</td>\n",
       "      <td>313</td>\n",
       "      <td>632</td>\n",
       "      <td>1223820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spanish</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>Porcelanato Abitare Be 20x120 Cm. Ceramica Por...</td>\n",
       "      <td>PORCELAIN_TILES</td>\n",
       "      <td>validation</td>\n",
       "      <td>[porcelanato, abitare, ceramica, portinari]</td>\n",
       "      <td>[2722, 4404, 1406, 4405]</td>\n",
       "      <td>427</td>\n",
       "      <td>632</td>\n",
       "      <td>1223820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spanish</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>Reconstruction Semi Di Lino Alfaparf Shampoo 1...</td>\n",
       "      <td>HAIR_SHAMPOOS_AND_CONDITIONERS</td>\n",
       "      <td>validation</td>\n",
       "      <td>[reconstruction, semi, lino, alfaparf, shampoo]</td>\n",
       "      <td>[1, 3365, 7502, 10919, 849]</td>\n",
       "      <td>194</td>\n",
       "      <td>632</td>\n",
       "      <td>1223820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language label_quality                                              title  \\\n",
       "0  spanish    unreliable                           Metal Biela Dw10 Hdi 2.0   \n",
       "1  spanish    unreliable  Repuestos Martillo Rotoprcutor Bosch Gshsce Po...   \n",
       "2  spanish    unreliable  Pesca Caña Pejerrey Colony Brava 3m Fibra De V...   \n",
       "3  spanish    unreliable  Porcelanato Abitare Be 20x120 Cm. Ceramica Por...   \n",
       "4  spanish    unreliable  Reconstruction Semi Di Lino Alfaparf Shampoo 1...   \n",
       "\n",
       "                         category       split  \\\n",
       "0                 ENGINE_BEARINGS  validation   \n",
       "1     ELECTRIC_DEMOLITION_HAMMERS  validation   \n",
       "2                    FISHING_RODS  validation   \n",
       "3                 PORCELAIN_TILES  validation   \n",
       "4  HAIR_SHAMPOOS_AND_CONDITIONERS  validation   \n",
       "\n",
       "                                     tokenized_title  \\\n",
       "0                                [metal, biela, hdi]   \n",
       "1  [repuestos, martillo, rotoprcutor, bosch, gshs...   \n",
       "2  [pesca, caña, pejerrey, colony, brava, fibra, ...   \n",
       "3        [porcelanato, abitare, ceramica, portinari]   \n",
       "4    [reconstruction, semi, lino, alfaparf, shampoo]   \n",
       "\n",
       "                                             data  target  n_labels     size  \n",
       "0                               [457, 1480, 3450]      88       632  1223820  \n",
       "1                    [3119, 892, 1, 767, 1, 9337]     174       632  1223820  \n",
       "2  [700, 990, 2057, 3990, 3670, 1737, 1153, 6568]     313       632  1223820  \n",
       "3                        [2722, 4404, 1406, 4405]     427       632  1223820  \n",
       "4                     [1, 3365, 7502, 10919, 849]     194       632  1223820  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenamos los sets de training, validation y testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>split</th>\n",
       "      <th>tokenized_title</th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "      <th>n_labels</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spanish</td>\n",
       "      <td>reliable</td>\n",
       "      <td>Casita Muñecas Barbies Pintadas</td>\n",
       "      <td>DOLLHOUSES</td>\n",
       "      <td>train</td>\n",
       "      <td>[casita, muñecas, barbies, pintadas]</td>\n",
       "      <td>[50001, 2, 50000, 3]</td>\n",
       "      <td>0</td>\n",
       "      <td>632</td>\n",
       "      <td>4895280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spanish</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>Neceser Cromado Holográfico</td>\n",
       "      <td>TOILETRY_BAGS</td>\n",
       "      <td>train</td>\n",
       "      <td>[neceser, cromado, holográfico]</td>\n",
       "      <td>[6, 4, 5]</td>\n",
       "      <td>1</td>\n",
       "      <td>632</td>\n",
       "      <td>4895280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spanish</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>Funda Asiento A Medida D20 Chevrolet</td>\n",
       "      <td>CAR_SEAT_COVERS</td>\n",
       "      <td>train</td>\n",
       "      <td>[funda, asiento, medida, chevrolet]</td>\n",
       "      <td>[9, 7, 10, 8]</td>\n",
       "      <td>2</td>\n",
       "      <td>632</td>\n",
       "      <td>4895280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spanish</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>Embrague Ford Focus One 1.8 8v Td (90cv) Desde...</td>\n",
       "      <td>AUTOMOTIVE_CLUTCH_KITS</td>\n",
       "      <td>train</td>\n",
       "      <td>[embrague, ford, focus, one]</td>\n",
       "      <td>[11, 13, 12, 14]</td>\n",
       "      <td>3</td>\n",
       "      <td>632</td>\n",
       "      <td>4895280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spanish</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>Bateria Panasonic Dmwbcf10 Lumix Dmc-fx60n Dmc...</td>\n",
       "      <td>CAMERA_BATTERIES</td>\n",
       "      <td>train</td>\n",
       "      <td>[bateria, panasonic, dmwbcf, lumix, dmc, fxn, ...</td>\n",
       "      <td>[15, 19, 17, 18, 16, 1, 1, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>632</td>\n",
       "      <td>4895280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language label_quality                                              title  \\\n",
       "0  spanish      reliable                    Casita Muñecas Barbies Pintadas   \n",
       "1  spanish    unreliable                       Neceser Cromado Holográfico    \n",
       "2  spanish    unreliable               Funda Asiento A Medida D20 Chevrolet   \n",
       "3  spanish    unreliable  Embrague Ford Focus One 1.8 8v Td (90cv) Desde...   \n",
       "4  spanish    unreliable  Bateria Panasonic Dmwbcf10 Lumix Dmc-fx60n Dmc...   \n",
       "\n",
       "                 category  split  \\\n",
       "0              DOLLHOUSES  train   \n",
       "1           TOILETRY_BAGS  train   \n",
       "2         CAR_SEAT_COVERS  train   \n",
       "3  AUTOMOTIVE_CLUTCH_KITS  train   \n",
       "4        CAMERA_BATTERIES  train   \n",
       "\n",
       "                                     tokenized_title  \\\n",
       "0               [casita, muñecas, barbies, pintadas]   \n",
       "1                    [neceser, cromado, holográfico]   \n",
       "2                [funda, asiento, medida, chevrolet]   \n",
       "3                       [embrague, ford, focus, one]   \n",
       "4  [bateria, panasonic, dmwbcf, lumix, dmc, fxn, ...   \n",
       "\n",
       "                            data  target  n_labels     size  \n",
       "0           [50001, 2, 50000, 3]       0       632  4895280  \n",
       "1                      [6, 4, 5]       1       632  4895280  \n",
       "2                  [9, 7, 10, 8]       2       632  4895280  \n",
       "3               [11, 13, 12, 14]       3       632  4895280  \n",
       "4  [15, 19, 17, 18, 16, 1, 1, 1]       4       632  4895280  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat(df_concat, ignore_index=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5cQ0ln6K89z"
   },
   "source": [
    "Chequeamos que las categorías en train y test sean las mismas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "RB9FX80RR4Iv"
   },
   "outputs": [],
   "source": [
    "n_categories = len(dataset.category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E3618aSYLDLI",
    "outputId": "43d42b72-6da7-4edb-9234-1267844474a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.category.unique()) == len(test_df.category.unique()) == len(validation_df.category.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEPiJJ_qlWFy"
   },
   "source": [
    "## Preprocesamiento\n",
    "\n",
    "Vamos a utilizar el siguiente procesador, visto en clase ([notebook 4](link)). Este se encargará de preprocesar el texto (i.e. normalizarlo) y transformará las palabras en índices de un diccionario para luego poder pasar una secuencia de palabras para buscar en la matriz de embeddings y así permitir mayor manipulación de los embeddings (en lugar de utilizar embeddings fijos).\n",
    "\n",
    "Vamos a estar trabajando con la librería [gensim](https://pypi.org/project/gensim/) previamente importada para el procesamiento del lenguaje natural.\n",
    "\n",
    "En cuanto los pasos de preprocesamiento realizados, permiten uniformizar el texto de la mejor manera posible y contemplan lo siguiente:\n",
    "\n",
    "*   Pasar el texto a minúsculas (lower case).\n",
    "*   Remover tags de HTML que puedan estar embebidas en el texto.\n",
    "*   Remover símbolos de puntuación.\n",
    "*   Limpiar espacios: remover espacios múltiples y espacios en exceso al inicio o al final del texto ('title').\n",
    "*   Remover valores numéricos.\n",
    "*   Remover stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "vmh3pqlflWFz"
   },
   "outputs": [],
   "source": [
    "class RawDataProcessor:\n",
    "    def __init__(self, \n",
    "                 dataset, \n",
    "                 ignore_header=True, \n",
    "                 filters=None, \n",
    "                 vocab_size=50000):\n",
    "        if filters:\n",
    "            self.filters = filters\n",
    "        else:\n",
    "            self.filters = [\n",
    "                lambda s: s.lower(),\n",
    "                preprocessing.strip_tags,\n",
    "                preprocessing.strip_punctuation,\n",
    "                preprocessing.strip_multiple_whitespaces,\n",
    "                preprocessing.strip_numeric,\n",
    "                preprocessing.remove_stopwords,\n",
    "                preprocessing.strip_short,\n",
    "            ]\n",
    "        \n",
    "        # Create dictionary based on all the reviews (with corresponding preprocessing)\n",
    "        # https://radimrehurek.com/gensim/corpora/dictionary.html\n",
    "        self.dictionary = corpora.Dictionary(\n",
    "            dataset[\"title\"].map(self._preprocess_string).tolist()\n",
    "        )\n",
    "        # Filter the dictionary with extremos words\n",
    "        # https://tedboy.github.io/nlps/generated/generated/gensim.corpora.Dictionary.filter_extremes.html?highlight=filter_extrem\n",
    " #       self.dictionary.filter_extremes(no_below=2, no_above=1, keep_n=vocab_size)\n",
    "        \n",
    "        # Make the indices continuous after some words have been removed\n",
    "        # https://tedboy.github.io/nlps/generated/generated/gensim.corpora.Dictionary.compactify.html\n",
    "        self.dictionary.compactify()\n",
    "        \n",
    "\n",
    "        self.idx_to_target = sorted(dataset[\"category\"].unique())\n",
    "        self.target_to_idx = {t: i for i, t in enumerate(self.idx_to_target)}\n",
    "\n",
    "\n",
    "    def _preprocess_string(self, string):\n",
    "        # https://radimrehurek.com/gensim/parsing/preprocessing.html#gensim.parsing.preprocessing.preprocess_string:~:text=gensim.parsing.preprocessing.preprocess_string\n",
    "        return preprocessing.preprocess_string(string, filters=self.filters)\n",
    "\n",
    "    def _sentence_to_indices(self, sentence):\n",
    "      # https://radimrehurek.com/gensim/corpora/dictionary.html#:~:text=doc2idx(document,via%20unknown_word_index.\n",
    "        return self.dictionary.doc2idx(sentence, unknown_word_index=1)\n",
    "    \n",
    "    def encode_data(self, data):\n",
    "        return self._sentence_to_indices(self._preprocess_string(data))\n",
    "    \n",
    "    def encode_target(self, target):\n",
    "        return self.target_to_idx[target]\n",
    "    \n",
    "    def __call__(self, item):\n",
    "        if isinstance(item[\"data\"], str):\n",
    "            data = self.encode_data(item[\"data\"])\n",
    "        else:\n",
    "            data = [self.encode_data(d) for d in item[\"data\"]]\n",
    "        \n",
    "        if isinstance(item[\"target\"], str):\n",
    "            target = self.encode_target(item[\"target\"])\n",
    "        else:\n",
    "            target = [self.encode_target(t) for t in item[\"target\"]]\n",
    "        \n",
    "        return {\n",
    "            \"data\": data,\n",
    "            \"target\": target\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYyDGXQYlWF1"
   },
   "source": [
    "## Lectura de datos\n",
    "\n",
    "Leemos los datos del MeLiChallenge para utilizarlos en el entrenamiento y evaluación del modelo. En este caso no es necesario dividirlos entre test y training, ya que los mismos ya se encuentran divididos como tal desde los archivos de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cAoItVk-lWF2",
    "outputId": "fc044ee1-fe98-4a38-e94f-198eb719c5d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded with 4895280 training elements, 1223820 validation elements and 63680 test elements\n",
      "Sample train element:\n",
      "{'data': [1, 2, 0, 3], 'target': 188}\n"
     ]
    }
   ],
   "source": [
    "preprocess = RawDataProcessor(dataset)\n",
    "\n",
    "train_dataset = MeLiChallengeDataset(train_data, transform=preprocess)\n",
    "\n",
    "validation_dataset = MeLiChallengeDataset(validation_data, transform=preprocess)\n",
    "\n",
    "test_dataset = MeLiChallengeDataset(test_data, transform=preprocess)\n",
    "\n",
    "print(f\"Datasets loaded with {len(train_dataset)} training elements, {len(validation_dataset)} validation elements and {len(test_dataset)} test elements\")\n",
    "print(f\"Sample train element:\\n{train_dataset[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gk0jiZSXlWF3"
   },
   "source": [
    "## Collation function\n",
    "\n",
    "Como en este caso trabajamos con secuencias de palabras (representadas por sus índices en un vocabulario), cuando queremos buscar un *batch* de datos, el `DataLoader` de PyTorch espera que los datos del *batch* tengan la misma dimensión (para poder llevarlos todos a un tensor de dimensión fija). Esto lo podemos lograr mediante el parámetro de `collate_fn`. En particular, esta función se encarga de tomar varios elementos de un `Dataset` y combinarlos de manera que puedan ser devueltos como un tensor de PyTorch.\n",
    "\n",
    "En nuestro caso, como se vio en clase, definimos un módulo `PadSequences` que toma un valor mínimo, opcionalmente un valor máximo y un valor de relleno (*pad*) y dada una lista de secuencias, devuelve un tensor con *padding* sobre dichas secuencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "1y7OrMIZlWF3"
   },
   "outputs": [],
   "source": [
    "class PadSequences:\n",
    "    def __init__(self, pad_value=0, max_length=None, min_length=1):\n",
    "        assert max_length is None or min_length <= max_length\n",
    "        self.pad_value = pad_value\n",
    "        self.max_length = max_length\n",
    "        self.min_length = min_length\n",
    "\n",
    "    def __call__(self, items):\n",
    "        data, target = list(zip(*[(item[\"data\"], item[\"target\"]) for item in items]))\n",
    "        seq_lengths = [len(d) for d in data]\n",
    "\n",
    "        if self.max_length:\n",
    "            max_length = self.max_length\n",
    "            seq_lengths = [min(self.max_length, l) for l in seq_lengths]\n",
    "        else:\n",
    "            max_length = max(self.min_length, max(seq_lengths))\n",
    "\n",
    "        data = [d[:l] + [self.pad_value] * (max_length - l)\n",
    "                for d, l in zip(data, seq_lengths)]\n",
    "            \n",
    "        return {\n",
    "            \"data\": torch.LongTensor(data),\n",
    "            \"target\": torch.LongTensor(target)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffTIjXIIlWF3"
   },
   "source": [
    "## DataLoaders\n",
    "\n",
    "Ya habiendo definido nuestros conjuntos de datos y nuestra `collation_fn`, podemos definir nuestros `DataLoader`, uno para entrenamiento y otro para evaluación. \n",
    "\n",
    "Notar que `shuffle = False` para el caso del loader de evaluación, dado que no queremos mezclar los valores de evaluación cada vez que evaluamos porque al evaluar mediante *mini-batchs* nos puede generar inconsistencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "_nDbLYnwlWF4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "pad_sequences = PadSequences()\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          collate_fn=pad_sequences, drop_last=False)\n",
    "\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                         collate_fn=pad_sequences, drop_last=False)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                         collate_fn=pad_sequences, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuuULUMKlWF4"
   },
   "source": [
    "## El modelo de clasificación\n",
    "\n",
    "Para clasificación utilizaremos un perceptrón multicapa de dos capas ocultas, como se vio en clase. \n",
    "\n",
    "El tamaño de las distintas capas ocultas y la capa de salida son parámetros del modelo. \n",
    "\n",
    "En particular, tenemos la capa de `Embeddings` que es rellenada con los valores de embeddings preentrenados (los de Glove en este caso). \n",
    "\n",
    "En el caso de la capa de salida, se asume que el número de nodos se corresponde con el número de categorías posibles, en este caso 632. Los valores de salida son continuos (y van de 0 a 1). Luego, para determinar la clase predicha por el modelo, por fuera de la arquitectura de la red neuronal tomamos el máximo de todos los valores de salida y asignamos al nodo con el valor máximo un 1, y al resto 0 (ver sección de MLflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "-DGxcn3ulWF4"
   },
   "outputs": [],
   "source": [
    "class MeLiChallengeClassifier(nn.Module):\n",
    "    def __init__(self, \n",
    "                 pretrained_embeddings_path, \n",
    "                 dictionary,\n",
    "                 vector_size,\n",
    "                 freeze_embedings,\n",
    "                 output_size,\n",
    "                 hidden1_size,\n",
    "                 hidden2_size):\n",
    "        super().__init__()\n",
    "        embeddings_matrix = torch.randn(len(dictionary), vector_size)\n",
    "        embeddings_matrix[0] = torch.zeros(vector_size)\n",
    "        with bz2.open(pretrained_embeddings_path, \"rt\") as fh:\n",
    "            for line in fh:\n",
    "                word, vector = line.strip().split(None, 1)\n",
    "                if word in dictionary.token2id:\n",
    "                    embeddings_matrix[dictionary.token2id[word]] =\\\n",
    "                        torch.FloatTensor([float(n) for n in vector.split()])\n",
    "        self.embeddings = nn.Embedding.from_pretrained(embeddings_matrix,\n",
    "                                                       freeze=freeze_embedings,\n",
    "                                                       padding_idx=0)\n",
    "        self.hidden1 = nn.Linear(vector_size, hidden1_size)\n",
    "        self.hidden2 = nn.Linear(hidden1_size, hidden2_size)\n",
    "        self.output = nn.Linear(hidden2_size, output_size)\n",
    "        self.vector_size = vector_size\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = torch.mean(x, dim=1)\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YP5SzP2QlWF5"
   },
   "source": [
    "## Experimento de MLflow\n",
    "\n",
    "Utilizamos MLflow para hacer un mejor seguimiento del experimento y registramos la siguiente información: parámetros, métricas, error y artefactos (resultados de la predicción).\n",
    "\n",
    "Seteamos los parámetros de antemano e hicimos las siguientes modificaciones respecto a la versión vista en clases:\n",
    "\n",
    "*   Utilizamos `balanced accuracy` como la métrica de evaluación, a modo de prevenir la influencia de desbalances en la distribución de clases en los datos\n",
    "*   Utilizamos Cross Entropy Loss dado que se trata de un problema de clasificación multi-clase\n",
    "*   Agregamos un paso previo a la evaluación de las predicciones, que toma el valor máximo de la capa de salida (output layer) y asigna 1 al nodo que tiene el valor máximo y 0 en los otros casos. De este modo nos aseguramos de que haya una sola clase como output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "tVGFQzOkRplR"
   },
   "outputs": [],
   "source": [
    "embedding_size = 300\n",
    "hidden1_size = 128*5\n",
    "hidden2_size = 128*5\n",
    "output_size = n_categories\n",
    "min_valid_loss = np.inf\n",
    "\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "185741df7265499b8f33b9bb4b0d410c",
      "29e8d469a66d4367bd5880448f4ccf9d",
      "ba1933dadd4a4488bad47e719c2b0258",
      "4af59d78040841c18f22779a6baf50ea",
      "d2eb637c20cc46d08ac6e92269e2dfce",
      "5460cde5c2064d2fa7b41ae637f327f1",
      "ce5ca883409446d296f1cf2d44697a7b",
      "f177ee2cad4c4c77af265a8a58651eb9",
      "05a19486d59840dbb1d4363b754386ed",
      "7d60b4a163e6425697add436182093a8",
      "aa91531115c74daf971a7167cde6ecd8",
      "a1538680593d412982cadb26c7c2331c",
      "f23de7c36c5441a6845d12fc66fe7a8d",
      "202c3435044347a49b293d463b516f41",
      "79f28171486342dd9bf8197006f1d17f",
      "f4ff00e61b194dc4a5dd63a74ae8f5b8",
      "6cb5350cdb6c4023af856e84b1529533",
      "d9ddaf9a88124abaa5789fdcb74b35f3",
      "e680ca1c1abc488a8e349b94dfbfa0d0",
      "76c2d28f9d004279a421d9467a9e3b02",
      "704f4afc2ef2460b9e0ad72d40e7d7d4",
      "a3dd8b1a75414ba7b97985b929643bdd"
     ]
    },
    "id": "ATF0NzLclWF5",
    "outputId": "de9ed864-684b-40c9-8fa5-aba3817f344a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/run/user/1000/app/com.jetbrains.PyCharm-Community/ipykernel_1157/1122330740.py:1: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  EXPERIMENT = f\"deep_learning_MLP_experiment_{pd.datetime.now().strftime('%Y-%m-%dT%H%M%S')}\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcc4748a943412ea3251882ea4960fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79b6c8d5d654d10b83769558a7ce135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EXPERIMENT = f\"deep_learning_MLP_experiment_{pd.datetime.now().strftime('%Y-%m-%dT%H%M%S')}\"\n",
    "\n",
    "mlflow.create_experiment(EXPERIMENT)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_name\", \"mlp\")\n",
    "    mlflow.log_param(\"freeze_embedding\", True)\n",
    "    mlflow.log_params({\n",
    "        \"embedding_size\": embedding_size,\n",
    "        \"hidden1_size\": hidden1_size,\n",
    "        \"hidden2_size\": hidden2_size\n",
    "    })\n",
    "    model = MeLiChallengeClassifier(path_embedding,\n",
    "                                    preprocess.dictionary,\n",
    "                                    embedding_size,\n",
    "                                    True,\n",
    "                                    output_size,\n",
    "                                    hidden1_size,\n",
    "                                    hidden2_size)\n",
    "    best_model_state = model.state_dict()\n",
    "    loss = nn.CrossEntropyLoss() # Usamos Cross Entropy Loss al tratarse de un multi-class classification problem\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    for epoch in trange(EPOCHS):\n",
    "        # Training step\n",
    "        model.train()\n",
    "        running_loss = []\n",
    "        for idx, batch in enumerate(tqdm(train_loader)):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch[\"data\"])\n",
    "            loss_value = loss(output, batch[\"target\"])\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            running_loss.append(loss_value.item())\n",
    "        # Logueamos métricas\n",
    "        mlflow.log_metric(\"train_loss\", sum(running_loss) / len(running_loss), epoch)\n",
    "        \n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        running_loss = []\n",
    "        targets = []\n",
    "        predictions = []\n",
    "        for batch in tqdm(validation_loader):\n",
    "            output = model(batch[\"data\"])\n",
    "            loss_value = loss(output, batch[\"target\"]).item()\n",
    "            running_loss.append(loss_value)\n",
    "            targets.extend(batch[\"target\"].numpy())\n",
    "            # Tomamos el índice del valor máximo para cada predicción\n",
    "            x = np.argmax(output.squeeze().detach().numpy(), axis=1)\n",
    "            predictions.extend(x)\n",
    "        if min_valid_loss > sum(running_loss):\n",
    "            min_valid_loss = sum(running_loss)\n",
    "            best_model_state = model.state_dict()\n",
    "        # Logueamos métricas\n",
    "        mlflow.log_metric(\"validation_loss\", sum(running_loss) / len(running_loss), epoch)\n",
    "        mlflow.log_metric(\"validation_balanced_accuracy\", balanced_accuracy_score(targets, predictions), epoch)\n",
    "        print(f\"Validation balanced accuracy: {balanced_accuracy_score(targets, predictions)}\")\n",
    "    \n",
    "    # Testing step\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        model.load_state_dict(best_model_state) # Cargamos el modelo cuyos parámetros corresponden a la menor loss\n",
    "        model.eval()\n",
    "        targets = []\n",
    "        predictions = []\n",
    "        for batch in tqdm(test_loader):\n",
    "            output = model(batch[\"data\"])\n",
    "            targets.extend(batch[\"target\"].numpy())\n",
    "            # Tomamos el índice del valor máximo para cada predicción\n",
    "            x = np.argmax(output.squeeze().detach().numpy(), axis=1)\n",
    "            predictions.extend(x)\n",
    "        # Calculamos la métrica\n",
    "        print(f\"Testing balanced accuracy: {balanced_accuracy_score(targets, predictions)}\")\n",
    "        # Guardamos las predicciones\n",
    "        pd.DataFrame({\"prediction\": predictions, \"target\": targets}).to_csv(\n",
    "            f\"{tmpdirname}/predictions.csv.gz\", index=False\n",
    "        )\n",
    "        # Guardamos el modelo\n",
    "        torch.save(model, f'{tmpdirname}/model.pth')\n",
    "        # Logueamos artefactos\n",
    "        mlflow.log_artifact(f\"{tmpdirname}/predictions.csv.gz\")\n",
    "        mlflow.log_artifact(f\"{tmpdirname}/model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DGuXVgXC5m-"
   },
   "source": [
    "Zipeamos la carpeta mlruns para poder descargarla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ZF6QbNKC996"
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(MLFLOW_PATH_ZIP):\n",
    "    os.remove(MLFLOW_PATH_ZIP)\n",
    "\n",
    "!zip -r {MLFLOW_PATH_ZIP} {MLFLOW_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sbLESzYIDHGg"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(MLFLOW_PATH_ZIP)\n",
    "except:\n",
    "    print(\"Running a Jupyter notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "A continuación mostramos los resultados, que luego comentaremos en la sección Conclusiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for measure in ['balanced_accuracy', 'train_loss', 'validation_loss']:\n",
    "    display(HTML(f\"{measure.replace('_', ' ').title()} vs Epochs\"))\n",
    "    display(Image(filename=os.path.join(IMAGES_PATH, f'{measure}_MLP_epochs_batch-size-128.png')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4noWCRf8jdSo"
   },
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtM0kB-jzFYB"
   },
   "source": [
    "Para este trabajo utilizamos de base los modelos, datasets, data loaders y funciones vistos en clase, pero realizando modificaciones necesarias para ajustarlas a este problema en particular, como mencionamos en las secciones anteriores.\n",
    "\n",
    "Los resultados obtenidos tuvieron un bajo balanced accuracy. Basados en la interpretación gráfica podemos observar que si bien es baja mejora a medida que avanzan los epochs, por lo cual una posibilidad de mejorar estas métricas sería aumentar el número de epochs.\n",
    "\n",
    "Otro factor que puede estar afectando el modelo es la calidad de las etiquetas, ya que sólo un bajo porcentaje de los registros tiene una etiqueta confiable (~8.5%). A esto se suma que el número de etiquetas a predecir es muy alto (632), por lo cual necesitaríamos un volumen importante de datos con buena calidad de etiquetas.\n",
    "\n",
    "Por otro lado, dada la alta dimensionalidad del problema: usamos embeddings de texto y además hay una alta cantidad de outputs del modelo, uno por cada categoría/etiqueta a predecir, lo adecuado sería aplicar una arquitectura más compleja que la utilizada dado que probablemente no puede generalizar bien debido a las limitaciones propias de este tipo de modelo (MLP).\n",
    "\n",
    "Como ya mencionamos, nuestro modelo necesita ser mejorado, ya sea cambiando de arquitectura o a través de la variación de hiperparámetros. Como pasos a seguir, podríamos probar con distintos hiperparámetros hasta obtener un modelo óptimo, e.g. haciendo un gridsearch o utilizando alguna librería como Optuna/Hyperopt. En línea con esto también se podría cambiar la arquitectura, aumentando la cantidad de capas y/o el número de nodos para probar si mejora el modelo, dado que probamos con una cantidad mínima de los mismos (2 capas y 640 nodos por capa) en pos de mantener los tiempos de ejecución en rangos razonables (<3-4 horas). Esto debería estar acompañado de un chequeo/mejora de la calidad de los datos para ver mejoras significativas en los resultados.\n",
    "\n",
    "Haciendo un análisis del error, vemos que tanto para el set de entrenamiento como el set de evaluación el error disminuye a medida que avanzan los epochs, lo cual indica que el modelo está \"aprendiendo\". No obstante, en ambos casos al tratarse de pocos epochs/ciclos no queda claro si las curvas podrían seguir descendiendo o si están prontas a estabilizarse, por lo que aumentando el número de epochs sería una forma de verificarlo. Esto último implica un mayor tiempo de entrenamiento, por lo cual no fue evaluado."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Slideshow",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "rise": {
   "scroll": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05a19486d59840dbb1d4363b754386ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "185741df7265499b8f33b9bb4b0d410c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_29e8d469a66d4367bd5880448f4ccf9d",
       "IPY_MODEL_ba1933dadd4a4488bad47e719c2b0258",
       "IPY_MODEL_4af59d78040841c18f22779a6baf50ea"
      ],
      "layout": "IPY_MODEL_d2eb637c20cc46d08ac6e92269e2dfce"
     }
    },
    "202c3435044347a49b293d463b516f41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e680ca1c1abc488a8e349b94dfbfa0d0",
      "max": 38245,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_76c2d28f9d004279a421d9467a9e3b02",
      "value": 27732
     }
    },
    "29e8d469a66d4367bd5880448f4ccf9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5460cde5c2064d2fa7b41ae637f327f1",
      "placeholder": "​",
      "style": "IPY_MODEL_ce5ca883409446d296f1cf2d44697a7b",
      "value": "  0%"
     }
    },
    "4af59d78040841c18f22779a6baf50ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d60b4a163e6425697add436182093a8",
      "placeholder": "​",
      "style": "IPY_MODEL_aa91531115c74daf971a7167cde6ecd8",
      "value": " 0/3 [00:00&lt;?, ?it/s]"
     }
    },
    "5460cde5c2064d2fa7b41ae637f327f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6cb5350cdb6c4023af856e84b1529533": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "704f4afc2ef2460b9e0ad72d40e7d7d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76c2d28f9d004279a421d9467a9e3b02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "79f28171486342dd9bf8197006f1d17f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_704f4afc2ef2460b9e0ad72d40e7d7d4",
      "placeholder": "​",
      "style": "IPY_MODEL_a3dd8b1a75414ba7b97985b929643bdd",
      "value": " 27731/38245 [1:24:38&lt;28:23,  6.17it/s]"
     }
    },
    "7d60b4a163e6425697add436182093a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1538680593d412982cadb26c7c2331c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f23de7c36c5441a6845d12fc66fe7a8d",
       "IPY_MODEL_202c3435044347a49b293d463b516f41",
       "IPY_MODEL_79f28171486342dd9bf8197006f1d17f"
      ],
      "layout": "IPY_MODEL_f4ff00e61b194dc4a5dd63a74ae8f5b8"
     }
    },
    "a3dd8b1a75414ba7b97985b929643bdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa91531115c74daf971a7167cde6ecd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba1933dadd4a4488bad47e719c2b0258": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f177ee2cad4c4c77af265a8a58651eb9",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_05a19486d59840dbb1d4363b754386ed",
      "value": 0
     }
    },
    "ce5ca883409446d296f1cf2d44697a7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d2eb637c20cc46d08ac6e92269e2dfce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9ddaf9a88124abaa5789fdcb74b35f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e680ca1c1abc488a8e349b94dfbfa0d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f177ee2cad4c4c77af265a8a58651eb9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f23de7c36c5441a6845d12fc66fe7a8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6cb5350cdb6c4023af856e84b1529533",
      "placeholder": "​",
      "style": "IPY_MODEL_d9ddaf9a88124abaa5789fdcb74b35f3",
      "value": " 73%"
     }
    },
    "f4ff00e61b194dc4a5dd63a74ae8f5b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
